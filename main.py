# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10s3Wf4OwOATYMDtf-JEFE0l_OqXP9pUC
"""

import torch
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
from model import CreditRiskNN
from utils import save_checkpoint, load_checkpoint, test_model, create_subset_loader, prepare_data_loaders, test_learning_rates

# Device setup
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
input_size = X_train.shape[1]
num_classes = 1
learning_rates = [0.001, 0.01, 0.1]
batch_size = 64
num_epochs = 15

# Data preparation
train_loader, test_loader, y_train_tensor = prepare_data_loaders(X_train, y_train, X_test, y_test, batch_size)

# Test different learning rates
best_lr, best_loss = test_learning_rates(CreditRiskNN, input_size, num_classes, device, small_train_loader, learning_rates)

# Model, criterion, optimizer, scheduler
model = CreditRiskNN(input_size=input_size, num_classes=num_classes).to(device)
pos_weight = torch.tensor((y_train_tensor == 0).sum().item() / (y_train_tensor == 1).sum().item()).to(device)
criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr, weight_decay=1e-5)
scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    # Initialize tqdm progress bar for the current epoch
    loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", leave=False)

    for batch_idx, (X_batch, y_batch) in enumerate(loop):

        X_batch, y_batch = X_batch.to(device).float(), y_batch.to(device).float()
        y_batch = y_batch.unsqueeze(1)

        # Zero the gradients
        optimizer.zero_grad()

        # Forward pass
        y_pred = model(X_batch)

        # Calculate loss
        loss = criterion(y_pred, y_batch)
        running_loss += loss.item()

        # Backward pass
        loss.backward()

        # Update weights
        optimizer.step()

        # Update tqdm description with running loss
        loop.set_postfix(loss=running_loss / (batch_idx + 1))

    # calculate the average loss for the epoch
    epoch_loss = running_loss / len(train_loader)
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")

    # Apply ReduceLROnPlateau scheduler after each epoch, passing the average loss
    scheduler.step(epoch_loss)

    # Save checkpoint
    checkpoint_dir = "/content/drive/MyDrive/model_checkpoints"
    checkpoint_filename = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch+1}.pth")
    save_checkpoint(model, optimizer, scheduler, epoch, epoch_loss, checkpoint_filename)

# Testing
test_model(model, test_loader, criterion, device)

# # Load the trained model from the saved checkpoint
checkpoint_path = os.path.join(os.getcwd(), 'Deep Learning Projects', 'Credit_Risk_Scoring_System', 'model.pth')
model, optimizer, epoch, loss = load_checkpoint(model, optimizer, scheduler, checkpoint_path)